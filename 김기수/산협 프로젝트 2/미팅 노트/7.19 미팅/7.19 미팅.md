7.12 미팅

---

- 지난 스터디 메모
    
    ---
    
    박찬서 : NIC 컨트롤러 -
    
    *** 인터럽트 모더레이션 - 패킷 갯수보다 하드웨어 인터럽트가 적음
    
    드라이버 하드웨어 인터럽트 → skb → napi
    
    각종 버퍼 종류 정리할 것.
    
    드라이버가 하는 일 → skb에 잘 넣어주는것.
    
    자료구조가 존재하는이유 : 소통을 위해서. 생성자랑 소비자가 다르기 때문에…
    
    디스크립터, 패킷버퍼 두개를 DMA 함.
    
    shallow buffer? SDRAM?
    
    hyperviser, VNIC,
    
    컨테이너 - resource isolation, namespace ???
    
    VM - 새로운 가상 컴퓨터
    
    vm이 vf를 물고 있고, host가 pf를 물고 있음. vf는 간단하게 구현되어 있고 pf가 많은 작업을 해주게 됨.
    
    ==주어와 목적어를 써보자..==
    
    tx에서 write-l(레지스터) 가 쓰이는데, 레지스터가 ioaddr로 들어갈테니 염두하고 확인해볼것.
    
    [[IOMMU와 Bus Register (1)]]
    
      
    
    링디스크립터를 DMA할때 주소를 어떤 주소를 넘기는지
    
    GRO 보충
    
    napi_schedule 이후 보기
    
    perf 더 공부해오기
    
    ---
    

  

### 주요 토픽

---

- Goodnote : struct 도식화에서 검색 가능 여부 - 글자 인식을 통해 일부 되긴하나 안되는 부분도 있어 시간 되는대로 text type으로 수정할 예정. / napi_struct, sk_buff, xdp_buff 등 일부 구조체 추가 완료 / softnet_data, irqaction_desc 등 추가적인 구조체 차후 추가 예정.

  

- [[IOMMU와 Bus Register]]
- 링 디스크립터가 dma 할당받는 순간으로, rx_ring의 dma 주소를 받아서 virtual address를 획득함.

  

- napi_schedule이후 net_rx_action 함수가 언제 어떻게 등록 되고, 해당 함수가 실행되어 polling 되는 과정을 확인함. napi와 gro간 유기적으로 연결되 있는 모습 또한 확인하였으나, gro는 아직 확인하지 못하였고, napi 또한 구체적인 메커니즘을 확인해야할 필요성을 느낌

  

- Perf 대신에 uftrace를 사용하면? - ~~파일의 소스코드에서 개선점을 찾아야 하므로 물론 커널 코드 분석도 중요하지만 iperf 프로그램 내에서 실행시간을 측정해야한다고 보아 현재 iperf3 컴파일 옵션 변경을 통해 uftrace로 되도록 한다.~~ perf는 user-level까지 분석해준다. 다만 컴파일 옵션을 지정하여 함수 이름을 남겨두어야 해석이 가능했고, user-level에서 주요한 함수들이 극히 적은 share를 가지고 있어 잘못 넘겨짚었다.  
    gcc 옵션 -pg를 통해 uftrace를 사용 → userspace 함수 실행시간이 iperf/output.txt로 저장되어 있고, 추가적으로 이를 perf를 통해 분석하였을 때 좀 더 프로그램의 함수이름이 식별가능해지는 장점을 얻게됨. 하나의 쓰레드에서 하나의 Nwrite이 실행되는 것을 볼 수 있었음.  
    시도해본 것으로 I/O 읽고 쓰기가 오버헤드가 되지 않을까라는 단순한 가정 하에 1048576길이의 char array로 바꿔서 실험해봄. 5Gbps 정도 나오다가 중간에 알 수 없는 오류로 멈춤. 좀더 통제된 환경에서 실험해볼 수 있다면 좋을 것 같음.  
      
    

  

- [[AF_XDP]] napi 관련 함수들을 공부하던 중 xdp가 중점적으로 나와 우선 간단하게 정리하였음. 이 것 또한 참고자료를 바탕으로 더 정리해나갈 예정.

  

- [[→ice_vsi_setup_rx_rings(vsi)]] dma를 중점적으로 봤을 때는 tx와 rx가 다를게 없다고 생각하였으나, napi 과정을 보며 다른 점이 많이 보이게 되어 새롭게 페이지를 작성하게 됨.

  

스터디 메모

---

황재훈 - NAPI 발표

GRO는 포인터만 옮기게 됨.

GFP - get free page, interrupt vector 공부 하기

top half bottom half가 정확하게 뭔지?

__napi_schedule 에서 rasie~ 는 irq를 끄고 하는것이라는 의미

napi 쓰레드가 인터럽터블이 아니면 비트만 셋팅하고 넘어감. 그게 아니면 직접 건드려서 napi가 되도록 하는 것임.

atomic operation - 병렬 처리 과정에서 동시성을 보장하기 위해 명령어 단에서 지원하는 것. 자체적인 큐가 있어서 명령어의 실행이 순차적으로 되게 만들게 됨.

guarantee → 학술적으로는 100% 보장할 떄 말하는 것임. 믿고 써도 됨.

XDP → 기존에는 커널을 컴파일을 띄워야함

추가적으로 로직을 추가해서 프로파일링이 가능하게 만들어줌

드라이버 단에 들어있는 trace point ⇒ XDP

시작지점, 끝지점을 찍어보는것

만들고 싶은 로직을 넣을 수도 있음

매번 컴파일을 안하고도 라이브 상태에서 삽입할 수 있음

AF_XDP 소켓 → 커널을 거치지 않고 바로 user space으로 꽂아줄 수 있음.

커널 코드 상에 어딘가에 이벤트, 혹은 코드를 지날 떄 임의의 코드를 실행시킬 수 있게 만들어줌.

XDP는 안따라가는 걸로.

  

전이중 통신을 하게 될 수 있으므로 Tx/Rx가 동시에 가능함.

디스크립터가 링구조임.

재활용→ 한바퀴 돌았을 떄 클린을 하게 됨. → 링버퍼로 사용할 수 있도록

napi_poll budget → 최종적으로 가져올 수 있는 최대 용량

디스크립터 공간, 메모리 공간

디스크립터는 재활용이 가능한데, 메모리 공간은 dma 필드의 주소를 통해 재할당하면 됨.

따라서 디스크립터는 init할때 dma하게 됨.

NIC head, tail register → tail은 내가 다음에 사용할 index값.

  

perf→ 주기적으로 어느 함수를 실행하고 있는지 체크하게 됨.

napi_gro_receive()