### Compile-Time QoS Scheme for Deep Learning Inferences
---
딥러닝 기술들이 time constraint를 잘 제공하지 않음. 따라서 스케쥴러가 아니라 컴파일 타임에 이를 다룰 수 있도록 하고자 하였음.

병렬처리, 동시처리 등을 하면서 약간의 지연시간이 생김. QoS가 낮아짐.

GPU는 task scheduling이 쉽지 않음.

10년간 상당히 연구된 분야임.

Preemption-based time sharing

Resource allocation/partitioning for spatial sharing

-> 시스템의 Throughput이 optimal 하지 않음.

스케줄러를 개발하는데 있어서 GPU kernel-mode driver section 밖에 스택이 없음.

이 단에서는 스케쥴러를 만드는데 큰 어려움이 있음. 또한 확장성도 별로임.

짧은 커널 코드들 수 백 개가 deeplearning inference의 주요한 task임.

temporal sharing / spatial sharing

kernel slicing을 하여 적절한 스케쥴링을 할 수 있다면 user의 demand를 충족할 수 있을 것으로 기대 됨.

DL 모델은 DAG로 나타낼 수 있음. => 방향 화살표로 연결된 노드들의 그래프

현대의 DL 컴파일러들은 high-level optimization을 하게 됨.
-> 같은 결과를 내는 더 저렴한 operator로 교체하거나, operator를 합쳐서 global memory를 덜 access 하게 만들고, 전체 모델을 topological sort를 통해 sequence of operator로 만들게 됨.

low-priority task를 slice하여 high-priority task의 QoS보장하기 위한 plan을 찾기 위함임.

reasonable한 search time을 주어야 함.

SM당 Thread block에 대한 마이크로 벤치마크를 시행함.

Thread block이 많은 커널부터 해야 효율성이 높음.

inference를 하나 실행하려면 여러 개의 커널을 실행해야 함. (sequence of kernels)

GPU는 SM을 여러 개 가진 장치

SM 하나가 동시에 여러개의 TB을 처리 할 수 있다.

wave는 100% GPU를 사용하는 커널들의 집합임.

flow wave가 아닌 커널들이 많으면 estimate가 힘들게 됨.

잘 모르겠다.