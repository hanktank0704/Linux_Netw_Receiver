Ref: 네트워킹시스템SW설계 강의 자료 - 황재현 교수님

![[Pasted image 20240920053724.png]]Sender에서는 메세지 send 시스템 콜 호출 시 Application-context thread가 Tx packet processing을 모두 처리하니 User-Kernel space 간 메세지 데이터 Copy를 수행할 때 Lock은 따로 필요하지 않다. 즉 send 시스템 콜을 호출하고 실제 패킷 전송까지 모두 수행하기 때문에, Sender에서는 패킷을 전송하는 타이밍이 정해져 있다.

다만 Receiver에서는 패킷이 도착하는 타이밍을 정확하게 알 수 없기도 하고, 그렇다고 소켓 버퍼를 계속 Polling한다고 하면 패킷이 도착할 때까지 다른 작업을 수행할 수 없어서 비효율적이다. 이러한 문제 Application-context thread와 Interrupt-context thread가 분리되어 동작한다.

먼저 Application thread는 소켓에 올라온 데이터만 가져가는 작업을 수행한다. read 시스템 콜 호출 시 user에서 kernel로 mode switching 후, Socket receive queue에 데이터가 있다면 user space buffer로 copy한다. 만약 Receive queue에 데이터가 없다면 thread가 blocking state로 대기한다. 

Socket receive queue에 데이터를 채우는 역할은 Interrupt-context의 Kernel thread가 수행한다. 패킷이 NIC에 도착하면 여러 개의 CPU 코어 중 하나와 연결되어 있는 Rx queue에 저장되고, 해당 queue와 연결된 코어에 Interrupt를 발생시켜 Packet processing이 시작된다. GRO 이후 Packet steering에 의해 이후 작업을 수행할 다른 코어가 선택될 수 있으며, 선택된 코어에서 Rx TCP/IP protocol processing을 수행하고 소켓의 Receive queue에 데이터를 추가한다.

문제는 두 thread가 동시에 Socket receive queue에서 데이터를 빼가거나 추가하기 때문에 Critical section이 만들어질 수밖에 없고, 각각의 thread는 Socket instance를 접근할 때 Lock을 걸고 접근해야 한다. 이러한 recv 시스템 콜(app-thread)과 TCP Receive Stack(intr-thread) 간의 상호작용은 실제 커널 코드 상에서도 확인할 수 있다.

[[tcp_recvmsg()]]
[[tcp_recvmsg_locked()]]
```C
int tcp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int flags,
		int *addr_len)
{
	...
	
	lock_sock(sk);
	ret = tcp_recvmsg_locked(sk, msg, len, flags, &tss, &cmsg_flags);
	release_sock(sk);
	
	...
}


static int tcp_recvmsg_locked(struct sock *sk, struct msghdr *msg, size_t len,
			      int flags, struct scm_timestamping_internal *tss,
			      int *cmsg_flags)
{
	...
	
	if (copied >= target) {
		/* Do not sleep, just process backlog. */
		__sk_flush_backlog(sk);
	} else {
		tcp_cleanup_rbuf(sk, copied);
		err = sk_wait_data(sk, &timeo, last);
		if (err < 0) {
			err = copied ? : err;
			goto out;
		}
	}
	
	...

	if (!(flags & MSG_TRUNC)) {
		err = skb_copy_datagram_msg(skb, offset, msg, used);
		if (err) {
			/* Exception. Bailout! */
			if (!copied)
				copied = -EFAULT;
			break;
		}
	}

	...
}
	```
Application thread에서 recv 시스템 콜을 호출하고 스택을 따라 쭉 내려오면 tcp_recvmsg()에서 Socket instance에 Lock을 잡고 tcp_recvmsg_locked()로 이어진다. 

tcp_recvmsg_locked()에서는 sk->sk_receive_queue에 붙은 skb들을 순회하며 User space로 데이터 Copy를 수행한다. 만약 target만큼 데이터 Copy를 충분히 수행하지 못한 경우 sk_wait_data()을 통해 Sleep하며, target만큼 Copy했다면 단순히 Sleep하지 않고 __ sk_flush_backlog()를 통해 소켓에 남은 backlog를 처리한다. 

[[release_sock()]]
[[__sk_flush_backlog()]]
[[__release_sock()]]
```C
void release_sock(struct sock *sk)
{
	...
	spin_lock_bh(&sk->sk_lock.slock);
	if (sk->sk_backlog.tail)
		__release_sock(sk);
	...
	
	spin_unlock_bh(&sk->sk_lock.slock);
}

void __sk_flush_backlog(struct sock *sk)
{
	...
	spin_lock_bh(&sk->sk_lock.slock);
	__release_sock(sk);
	...
}

void __release_sock(struct sock *sk)
	__releases(&sk->sk_lock.slock)
	__acquires(&sk->sk_lock.slock)
{
	struct sk_buff *skb, *next;

	while ((skb = sk->sk_backlog.head) != NULL) {
		sk->sk_backlog.head = sk->sk_backlog.tail = NULL;

		spin_unlock_bh(&sk->sk_lock.slock);

		do {
			next = skb->next;
			prefetch(next);
			DEBUG_NET_WARN_ON_ONCE(skb_dst_is_noref(skb));
			skb_mark_not_on_list(skb);
			sk_backlog_rcv(sk, skb);

			cond_resched();

			skb = next;
		} while (skb != NULL);

		spin_lock_bh(&sk->sk_lock.slock); // bh: bottom-half
	}
	...
}
```

__ sk_flush_backlog 및 release_sock()에서는 sk->sk_backlog를 통해 처리할 backlog가 있다면 __ release_sock()으로 이어진다. 
__ release_sock()는 sk->sk_backlog를 순회하며 sk_backlog_rcv() 함수를 호출하는데, 이 함수 안에서 tcp_v4_do_rcv()를 호출하며 TCP protocol processing을 수행한다.


[[Encyclopedia of NetworkSystem/Function/net-ipv4/tcp_v4_rcv()|tcp_v4_rcv()]]
[[Encyclopedia of NetworkSystem/Function/net-ipv4/tcp_v4_do_rcv()|tcp_v4_do_rcv()]]
```C
int tcp_v4_rcv(struct sk_buff *skb)
{
	...
	
	ret = 0;
	if (!sock_owned_by_user(sk)) {
		ret = tcp_v4_do_rcv(sk, skb);
	} else {
		if (tcp_add_backlog(sk, skb, &drop_reason))
			goto discard_and_relse;
	}
	bh_unlock_sock(sk);

	...
}
```

tcp_v4_rcv() 이후 tcp_v4_do_rcv() 부터는 sk instance를 필요로 하며, 이 때문에 !sock_owned_by_user(sk)을 통해 다른 thread가 sk instance를 소유하고 있지 않은지, 즉 Lock을 얻을 수 있는지 확인하고 나서야 TCP protocol processing을 수행할 수 있다.

